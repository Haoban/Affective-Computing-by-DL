{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (Bonus Task). Emotion Recognition using mutiple signals with deep learning\n",
    "### Objective\n",
    "\n",
    "**This exercise task asks you to design deep learning based emotion recognition using multiple signals**.\n",
    "Generally speaking, you are asked to predict the emotion with the facial expression and audio features in Task 1. \n",
    "In this task, you need to use the fully conncted layers which we have used in the bonus task of Exercise 1 and 2. \n",
    "\n",
    "You can use the facial expression and audio features in Task 2. Different from exercise 1 and 2. You do not need to extract features with convolutional layers from images and audios. You can use the facial expression and audio features directly and input the feautures into the network.\n",
    "\n",
    "In order to utilize facial expression and audio features, you can combine them together as a new feature or you can train a two-path network and fuse the scores. \n",
    "\n",
    "In this bonus task, you need to define the network architecture using pytorch, and you will need to invoke it in your training and evaluation code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested procedures\n",
    "\n",
    "We provide following procedures to support you to complete this exercise. But you are free to achieve the exercise goal by your own way of implementation.\n",
    "\n",
    "1. Load facial expression and audio features. Process the features form different modalities to the equal length through CCA following task 2.\n",
    "\n",
    "2. Combine the facial expression and audio features and input the feature to the network. Or train facial expression and audio features seprately and combine the scores in the network. \n",
    "\n",
    "3. Initialize the network and perform the training\n",
    "\n",
    "4. Evaluate the trained mode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code snippet of the network architecture\n",
    "You need to define your whole network structure in __init__() fuction and the forward() function, following bonus tasks in exercise 1 and 2. For the network design, as we input extracted features, only fully connected layer is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FusionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, n_hidden, out_dim):\n",
    "       \n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden)\n",
    "        self.layer2 = nn.Linear(n_hidden, out_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden), nn.BatchNorm1d(n_hidden), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden, out_dim))\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        lay_out1 = F.relu(self.layer1(x))        \n",
    "        lay_out2 = self.layer2(lay_out1)\n",
    "        \n",
    "        return lay_out2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation\n",
    "Please write your code below to complete the exercise\n",
    "\n",
    "\n",
    "#### Load and re-orgnize the data\n",
    "\n",
    "1. Load the facial and audio data in task 2. Different from SVM, the deep learning requires the class label starting with 0. So, you need to re-orgnize the class label to 0 and 1.\n",
    "\n",
    "2. Combine the facial and audio features. As the features have different length. We firstly map them to same length with CCA following Task 2.  You can also train them seprately and fuse the scores in the network.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage import transform\n",
    "from skimage import color\n",
    "from skimage import img_as_ubyte\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import sklearn\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "\n",
    "mdata = sio.loadmat('lab3_data.mat')\n",
    "\n",
    "#facial expression training and testing data, training and testing class and transfrom the labels to 0 and 1.\n",
    "\n",
    "training_data = mdata['training_data']\n",
    "testing_data = mdata['testing_data']\n",
    "training_class =  mdata['training_class']\n",
    "testing_class = mdata['testing_class']\n",
    "\n",
    "\n",
    "#audio training and testing data\n",
    "training_data_proso = mdata['training_data_proso']\n",
    "testing_data_proso = mdata['testing_data_proso']\n",
    "\n",
    "# Re-organize the class label\n",
    "\n",
    "retraining_class = []\n",
    "retesting_class = []\n",
    "for i in range(len(training_class)):\n",
    "    retraining_class.append([0 if training_class[i] == 1 else 1])\n",
    "for i in range(len(testing_class)):\n",
    "    retesting_class.append([0 if testing_class[i] == 1 else 1])\n",
    "    \n",
    "retraining_class = np.array(retraining_class).astype(training_class[0][0])\n",
    "retesting_class = np.array(retesting_class).astype(testing_class[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "import numpy as np\n",
    "\n",
    "#Use CCA to construct the Canonical Projective Vector (CPV) and calculate CCA features\n",
    "cca = CCA(n_components=15)\n",
    "cca.fit(training_data, training_data_proso)\n",
    "\n",
    "v_train_cca , a_train_cca = cca.transform(training_data ,training_data_proso)\n",
    "v_test_cca , a_test_cca = cca.transform(testing_data, testing_data_proso)\n",
    "\n",
    "# Concatenate multiple feature for training data and testing data respectively\n",
    "\n",
    "training_CCDF = np.concatenate((v_train_cca ,a_train_cca),axis=1)\n",
    "testing_CCDF = np.concatenate((v_test_cca ,a_test_cca),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the network training.\n",
    "\n",
    "Please write your code below for the network training. Please accumulate the loss and classification accuracy for each epoch and output them and the end of the epoch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(training_CCDF.astype(np.float))\n",
    "labels = torch.LongTensor(retraining_class.reshape(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20Train loss: 0.020Train accuracy: 38.000\n",
      "Epoch 2/20Train loss: 0.017Train accuracy: 52.000\n",
      "Epoch 3/20Train loss: 0.014Train accuracy: 64.000\n",
      "Epoch 4/20Train loss: 0.013Train accuracy: 72.000\n",
      "Epoch 5/20Train loss: 0.012Train accuracy: 76.000\n",
      "Epoch 6/20Train loss: 0.011Train accuracy: 78.000\n",
      "Epoch 7/20Train loss: 0.010Train accuracy: 78.000\n",
      "Epoch 8/20Train loss: 0.009Train accuracy: 82.000\n",
      "Epoch 9/20Train loss: 0.008Train accuracy: 84.000\n",
      "Epoch 10/20Train loss: 0.008Train accuracy: 86.000\n",
      "Epoch 11/20Train loss: 0.007Train accuracy: 88.000\n",
      "Epoch 12/20Train loss: 0.006Train accuracy: 94.000\n",
      "Epoch 13/20Train loss: 0.006Train accuracy: 98.000\n",
      "Epoch 14/20Train loss: 0.005Train accuracy: 100.000\n",
      "Epoch 15/20Train loss: 0.005Train accuracy: 100.000\n",
      "Epoch 16/20Train loss: 0.005Train accuracy: 100.000\n",
      "Epoch 17/20Train loss: 0.004Train accuracy: 100.000\n",
      "Epoch 18/20Train loss: 0.004Train accuracy: 100.000\n",
      "Epoch 19/20Train loss: 0.004Train accuracy: 100.000\n",
      "Epoch 20/20Train loss: 0.004Train accuracy: 100.000\n"
     ]
    }
   ],
   "source": [
    "trainingEpoch=20\n",
    "LEARNING_RATE=0.1\n",
    "\n",
    "inDim = training_CCDF.shape[1]\n",
    "outDim = 2\n",
    "hidden = 10\n",
    "\n",
    "batch_loss = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "#Initialize the network and optimizer\n",
    "model = FusionNet(inDim, hidden, outDim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Declare the optimizer for the network\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "##########\n",
    "inputs = torch.from_numpy(training_CCDF.astype(np.float))\n",
    "\n",
    "#input the data to the model to train\n",
    "for epoch in range(trainingEpoch):\n",
    "    train_len = 0\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs.float())\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "#     print(preds)\n",
    "#     print(labels)\n",
    "    loss = criterion(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "    running_corrects += torch.sum(preds == labels)\n",
    "    model.eval()\n",
    "    train_len += labels.size(0)\n",
    "    print(f\"Epoch {epoch+1}/{trainingEpoch}\"\n",
    "      f\"Train loss: {running_loss/len(preds):.3f}\"\n",
    "      f\"Train accuracy: {100*running_corrects.double()/train_len:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conduct the network evaluation\n",
    "\n",
    "Please write your code below to evaluated the trained model using your testing data. Please output the loss and accuracy of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(testing_CCDF.astype(np.float))\n",
    "labels = torch.LongTensor(retesting_class.reshape(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.003Test accuracy: 100.000\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_corrects = 0\n",
    "test_len =0\n",
    "\n",
    "\n",
    "outputs = model(inputs.float())\n",
    "_, preds = torch.max(outputs, 1)\n",
    "batch_loss = criterion(outputs, labels)\n",
    "test_loss = batch_loss.item()\n",
    "test_corrects = torch.sum(preds == labels.data)\n",
    "test_len = labels.size(0)\n",
    "test_losses.append(test_loss/len(preds))\n",
    "    \n",
    "print(f\"Test loss: {test_loss/len(preds):.3f}\"\n",
    "    f\"Test accuracy: {100*test_corrects.double()/test_len:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
